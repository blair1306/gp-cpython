<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>pyatomic.h source code [codebrowser/Include/pyatomic.h] - Woboq Code Browser</title>
<link rel="stylesheet" href="../../../data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="../../../data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="../../../data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="../../../data/jquery/jquery-ui.min.js"></script>
<script>var file = 'codebrowser/Include/pyatomic.h'; var root_path = '../..'; var data_path = '../../../data';</script>
<script src='../../../data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='..'>codebrowser</a>/<a href='./'>Include</a>/<a href='pyatomic.h.html'>pyatomic.h</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><u>#<span data-ppcond="1">ifndef</span> <span class="macro" data-ref="_M/Py_ATOMIC_H">Py_ATOMIC_H</span></u></td></tr>
<tr><th id="2">2</th><td><u>#define <dfn class="macro" id="_M/Py_ATOMIC_H" data-ref="_M/Py_ATOMIC_H">Py_ATOMIC_H</dfn></u></td></tr>
<tr><th id="3">3</th><td><u>#<span data-ppcond="3">ifdef</span> <span class="macro" data-ref="_M/Py_BUILD_CORE">Py_BUILD_CORE</span></u></td></tr>
<tr><th id="4">4</th><td></td></tr>
<tr><th id="5">5</th><td><u>#include "dynamic_annotations.h"</u></td></tr>
<tr><th id="6">6</th><td></td></tr>
<tr><th id="7">7</th><td><u>#include "pyconfig.h"</u></td></tr>
<tr><th id="8">8</th><td></td></tr>
<tr><th id="9">9</th><td><u>#if defined(HAVE_STD_ATOMIC)</u></td></tr>
<tr><th id="10">10</th><td><u>#include &lt;stdatomic.h&gt;</u></td></tr>
<tr><th id="11">11</th><td><u>#endif</u></td></tr>
<tr><th id="12">12</th><td></td></tr>
<tr><th id="13">13</th><td></td></tr>
<tr><th id="14">14</th><td><u>#if defined(_MSC_VER)</u> </td></tr>
<tr><th id="15">15</th><td><u>#include &lt;intrin.h&gt;</u></td></tr>
<tr><th id="16">16</th><td><u>#include &lt;immintrin.h&gt;</u></td></tr>
<tr><th id="17">17</th><td><u>#endif</u></td></tr>
<tr><th id="18">18</th><td></td></tr>
<tr><th id="19">19</th><td><i>/* This is modeled after the atomics interface from C1x, according to</i></td></tr>
<tr><th id="20">20</th><td><i> * the draft at</i></td></tr>
<tr><th id="21">21</th><td><i> * <a href="http://www.open-std.org/JTC1/SC22/wg14/www/docs/n1425.pdf">http://www.open-std.org/JTC1/SC22/wg14/www/docs/n1425.pdf</a>.</i></td></tr>
<tr><th id="22">22</th><td><i> * Operations and types are named the same except with a _Py_ prefix</i></td></tr>
<tr><th id="23">23</th><td><i> * and have the same semantics.</i></td></tr>
<tr><th id="24">24</th><td><i> *</i></td></tr>
<tr><th id="25">25</th><td><i> * Beware, the implementations here are deep magic.</i></td></tr>
<tr><th id="26">26</th><td><i> */</i></td></tr>
<tr><th id="27">27</th><td></td></tr>
<tr><th id="28">28</th><td><u>#if defined(HAVE_STD_ATOMIC)</u></td></tr>
<tr><th id="29">29</th><td></td></tr>
<tr><th id="30">30</th><td><b>typedef</b> <b>enum</b> _Py_memory_order {</td></tr>
<tr><th id="31">31</th><td>    _Py_memory_order_relaxed = memory_order_relaxed,</td></tr>
<tr><th id="32">32</th><td>    _Py_memory_order_acquire = memory_order_acquire,</td></tr>
<tr><th id="33">33</th><td>    _Py_memory_order_release = memory_order_release,</td></tr>
<tr><th id="34">34</th><td>    _Py_memory_order_acq_rel = memory_order_acq_rel,</td></tr>
<tr><th id="35">35</th><td>    _Py_memory_order_seq_cst = memory_order_seq_cst</td></tr>
<tr><th id="36">36</th><td>} _Py_memory_order;</td></tr>
<tr><th id="37">37</th><td></td></tr>
<tr><th id="38">38</th><td><b>typedef</b> <b>struct</b> _Py_atomic_address {</td></tr>
<tr><th id="39">39</th><td>    atomic_uintptr_t _value;</td></tr>
<tr><th id="40">40</th><td>} _Py_atomic_address;</td></tr>
<tr><th id="41">41</th><td></td></tr>
<tr><th id="42">42</th><td><b>typedef</b> <b>struct</b> _Py_atomic_int {</td></tr>
<tr><th id="43">43</th><td>    atomic_int _value;</td></tr>
<tr><th id="44">44</th><td>} _Py_atomic_int;</td></tr>
<tr><th id="45">45</th><td></td></tr>
<tr><th id="46">46</th><td><u>#define _Py_atomic_signal_fence(/*memory_order*/ ORDER) \</u></td></tr>
<tr><th id="47">47</th><td><u>    atomic_signal_fence(ORDER)</u></td></tr>
<tr><th id="48">48</th><td></td></tr>
<tr><th id="49">49</th><td><u>#define _Py_atomic_thread_fence(/*memory_order*/ ORDER) \</u></td></tr>
<tr><th id="50">50</th><td><u>    atomic_thread_fence(ORDER)</u></td></tr>
<tr><th id="51">51</th><td></td></tr>
<tr><th id="52">52</th><td><u>#define _Py_atomic_store_explicit(ATOMIC_VAL, NEW_VAL, ORDER) \</u></td></tr>
<tr><th id="53">53</th><td><u>    atomic_store_explicit(&amp;(ATOMIC_VAL)-&gt;_value, NEW_VAL, ORDER)</u></td></tr>
<tr><th id="54">54</th><td></td></tr>
<tr><th id="55">55</th><td><u>#define _Py_atomic_load_explicit(ATOMIC_VAL, ORDER) \</u></td></tr>
<tr><th id="56">56</th><td><u>    atomic_load_explicit(&amp;(ATOMIC_VAL)-&gt;_value, ORDER)</u></td></tr>
<tr><th id="57">57</th><td></td></tr>
<tr><th id="58">58</th><td><i>/* Use builtin atomic operations in GCC &gt;= 4.7 */</i></td></tr>
<tr><th id="59">59</th><td><u>#elif defined(HAVE_BUILTIN_ATOMIC)</u></td></tr>
<tr><th id="60">60</th><td></td></tr>
<tr><th id="61">61</th><td><b>typedef</b> <b>enum</b> _Py_memory_order {</td></tr>
<tr><th id="62">62</th><td>    _Py_memory_order_relaxed = __ATOMIC_RELAXED,</td></tr>
<tr><th id="63">63</th><td>    _Py_memory_order_acquire = __ATOMIC_ACQUIRE,</td></tr>
<tr><th id="64">64</th><td>    _Py_memory_order_release = __ATOMIC_RELEASE,</td></tr>
<tr><th id="65">65</th><td>    _Py_memory_order_acq_rel = __ATOMIC_ACQ_REL,</td></tr>
<tr><th id="66">66</th><td>    _Py_memory_order_seq_cst = __ATOMIC_SEQ_CST</td></tr>
<tr><th id="67">67</th><td>} _Py_memory_order;</td></tr>
<tr><th id="68">68</th><td></td></tr>
<tr><th id="69">69</th><td><b>typedef</b> <b>struct</b> _Py_atomic_address {</td></tr>
<tr><th id="70">70</th><td>    uintptr_t _value;</td></tr>
<tr><th id="71">71</th><td>} _Py_atomic_address;</td></tr>
<tr><th id="72">72</th><td></td></tr>
<tr><th id="73">73</th><td><b>typedef</b> <b>struct</b> _Py_atomic_int {</td></tr>
<tr><th id="74">74</th><td>    <em>int</em> _value;</td></tr>
<tr><th id="75">75</th><td>} _Py_atomic_int;</td></tr>
<tr><th id="76">76</th><td></td></tr>
<tr><th id="77">77</th><td><u>#define _Py_atomic_signal_fence(/*memory_order*/ ORDER) \</u></td></tr>
<tr><th id="78">78</th><td><u>    __atomic_signal_fence(ORDER)</u></td></tr>
<tr><th id="79">79</th><td></td></tr>
<tr><th id="80">80</th><td><u>#define _Py_atomic_thread_fence(/*memory_order*/ ORDER) \</u></td></tr>
<tr><th id="81">81</th><td><u>    __atomic_thread_fence(ORDER)</u></td></tr>
<tr><th id="82">82</th><td></td></tr>
<tr><th id="83">83</th><td><u>#define _Py_atomic_store_explicit(ATOMIC_VAL, NEW_VAL, ORDER) \</u></td></tr>
<tr><th id="84">84</th><td><u>    (assert((ORDER) == __ATOMIC_RELAXED                       \</u></td></tr>
<tr><th id="85">85</th><td><u>            || (ORDER) == __ATOMIC_SEQ_CST                    \</u></td></tr>
<tr><th id="86">86</th><td><u>            || (ORDER) == __ATOMIC_RELEASE),                  \</u></td></tr>
<tr><th id="87">87</th><td><u>     __atomic_store_n(&amp;(ATOMIC_VAL)-&gt;_value, NEW_VAL, ORDER))</u></td></tr>
<tr><th id="88">88</th><td></td></tr>
<tr><th id="89">89</th><td><u>#define _Py_atomic_load_explicit(ATOMIC_VAL, ORDER)           \</u></td></tr>
<tr><th id="90">90</th><td><u>    (assert((ORDER) == __ATOMIC_RELAXED                       \</u></td></tr>
<tr><th id="91">91</th><td><u>            || (ORDER) == __ATOMIC_SEQ_CST                    \</u></td></tr>
<tr><th id="92">92</th><td><u>            || (ORDER) == __ATOMIC_ACQUIRE                    \</u></td></tr>
<tr><th id="93">93</th><td><u>            || (ORDER) == __ATOMIC_CONSUME),                  \</u></td></tr>
<tr><th id="94">94</th><td><u>     __atomic_load_n(&amp;(ATOMIC_VAL)-&gt;_value, ORDER))</u></td></tr>
<tr><th id="95">95</th><td></td></tr>
<tr><th id="96">96</th><td><i>/* Only support GCC (for expression statements) and x86 (for simple</i></td></tr>
<tr><th id="97">97</th><td><i> * atomic semantics) and MSVC x86/x64/ARM */</i></td></tr>
<tr><th id="98">98</th><td><u>#elif defined(__GNUC__) &amp;&amp; (defined(__i386__) || defined(__amd64))</u></td></tr>
<tr><th id="99">99</th><td><b>typedef</b> <b>enum</b> _Py_memory_order {</td></tr>
<tr><th id="100">100</th><td>    _Py_memory_order_relaxed,</td></tr>
<tr><th id="101">101</th><td>    _Py_memory_order_acquire,</td></tr>
<tr><th id="102">102</th><td>    _Py_memory_order_release,</td></tr>
<tr><th id="103">103</th><td>    _Py_memory_order_acq_rel,</td></tr>
<tr><th id="104">104</th><td>    _Py_memory_order_seq_cst</td></tr>
<tr><th id="105">105</th><td>} _Py_memory_order;</td></tr>
<tr><th id="106">106</th><td></td></tr>
<tr><th id="107">107</th><td><b>typedef</b> <b>struct</b> _Py_atomic_address {</td></tr>
<tr><th id="108">108</th><td>    uintptr_t _value;</td></tr>
<tr><th id="109">109</th><td>} _Py_atomic_address;</td></tr>
<tr><th id="110">110</th><td></td></tr>
<tr><th id="111">111</th><td><b>typedef</b> <b>struct</b> _Py_atomic_int {</td></tr>
<tr><th id="112">112</th><td>    <em>int</em> _value;</td></tr>
<tr><th id="113">113</th><td>} _Py_atomic_int;</td></tr>
<tr><th id="114">114</th><td></td></tr>
<tr><th id="115">115</th><td></td></tr>
<tr><th id="116">116</th><td><em>static</em> <b>__inline__</b> <em>void</em></td></tr>
<tr><th id="117">117</th><td>_Py_atomic_signal_fence(_Py_memory_order order)</td></tr>
<tr><th id="118">118</th><td>{</td></tr>
<tr><th id="119">119</th><td>    <b>if</b> (order != _Py_memory_order_relaxed)</td></tr>
<tr><th id="120">120</th><td>        <b>__asm__</b> <em>volatile</em>(<q>""</q>:::<q>"memory"</q>);</td></tr>
<tr><th id="121">121</th><td>}</td></tr>
<tr><th id="122">122</th><td></td></tr>
<tr><th id="123">123</th><td><em>static</em> <b>__inline__</b> <em>void</em></td></tr>
<tr><th id="124">124</th><td>_Py_atomic_thread_fence(_Py_memory_order order)</td></tr>
<tr><th id="125">125</th><td>{</td></tr>
<tr><th id="126">126</th><td>    <b>if</b> (order != _Py_memory_order_relaxed)</td></tr>
<tr><th id="127">127</th><td>        <b>__asm__</b> <em>volatile</em>(<q>"mfence"</q>:::<q>"memory"</q>);</td></tr>
<tr><th id="128">128</th><td>}</td></tr>
<tr><th id="129">129</th><td></td></tr>
<tr><th id="130">130</th><td><i>/* Tell the race checker about this operation's effects. */</i></td></tr>
<tr><th id="131">131</th><td><em>static</em> <b>__inline__</b> <em>void</em></td></tr>
<tr><th id="132">132</th><td>_Py_ANNOTATE_MEMORY_ORDER(<em>const</em> <em>volatile</em> <em>void</em> *address, _Py_memory_order order)</td></tr>
<tr><th id="133">133</th><td>{</td></tr>
<tr><th id="134">134</th><td>    (<em>void</em>)address;              <i>/* shut up -Wunused-parameter */</i></td></tr>
<tr><th id="135">135</th><td>    <b>switch</b>(order) {</td></tr>
<tr><th id="136">136</th><td>    <b>case</b> _Py_memory_order_release:</td></tr>
<tr><th id="137">137</th><td>    <b>case</b> _Py_memory_order_acq_rel:</td></tr>
<tr><th id="138">138</th><td>    <b>case</b> _Py_memory_order_seq_cst:</td></tr>
<tr><th id="139">139</th><td>        _Py_ANNOTATE_HAPPENS_BEFORE(address);</td></tr>
<tr><th id="140">140</th><td>        <b>break</b>;</td></tr>
<tr><th id="141">141</th><td>    <b>case</b> _Py_memory_order_relaxed:</td></tr>
<tr><th id="142">142</th><td>    <b>case</b> _Py_memory_order_acquire:</td></tr>
<tr><th id="143">143</th><td>        <b>break</b>;</td></tr>
<tr><th id="144">144</th><td>    }</td></tr>
<tr><th id="145">145</th><td>    <b>switch</b>(order) {</td></tr>
<tr><th id="146">146</th><td>    <b>case</b> _Py_memory_order_acquire:</td></tr>
<tr><th id="147">147</th><td>    <b>case</b> _Py_memory_order_acq_rel:</td></tr>
<tr><th id="148">148</th><td>    <b>case</b> _Py_memory_order_seq_cst:</td></tr>
<tr><th id="149">149</th><td>        _Py_ANNOTATE_HAPPENS_AFTER(address);</td></tr>
<tr><th id="150">150</th><td>        <b>break</b>;</td></tr>
<tr><th id="151">151</th><td>    <b>case</b> _Py_memory_order_relaxed:</td></tr>
<tr><th id="152">152</th><td>    <b>case</b> _Py_memory_order_release:</td></tr>
<tr><th id="153">153</th><td>        <b>break</b>;</td></tr>
<tr><th id="154">154</th><td>    }</td></tr>
<tr><th id="155">155</th><td>}</td></tr>
<tr><th id="156">156</th><td></td></tr>
<tr><th id="157">157</th><td><u>#define _Py_atomic_store_explicit(ATOMIC_VAL, NEW_VAL, ORDER) \</u></td></tr>
<tr><th id="158">158</th><td><u>    __extension__ ({ \</u></td></tr>
<tr><th id="159">159</th><td><u>        __typeof__(ATOMIC_VAL) atomic_val = ATOMIC_VAL; \</u></td></tr>
<tr><th id="160">160</th><td><u>        __typeof__(atomic_val-&gt;_value) new_val = NEW_VAL;\</u></td></tr>
<tr><th id="161">161</th><td><u>        volatile __typeof__(new_val) *volatile_data = &amp;atomic_val-&gt;_value; \</u></td></tr>
<tr><th id="162">162</th><td><u>        _Py_memory_order order = ORDER; \</u></td></tr>
<tr><th id="163">163</th><td><u>        _Py_ANNOTATE_MEMORY_ORDER(atomic_val, order); \</u></td></tr>
<tr><th id="164">164</th><td><u>        \</u></td></tr>
<tr><th id="165">165</th><td><u>        /* Perform the operation. */ \</u></td></tr>
<tr><th id="166">166</th><td><u>        _Py_ANNOTATE_IGNORE_WRITES_BEGIN(); \</u></td></tr>
<tr><th id="167">167</th><td><u>        switch(order) { \</u></td></tr>
<tr><th id="168">168</th><td><u>        case _Py_memory_order_release: \</u></td></tr>
<tr><th id="169">169</th><td><u>            _Py_atomic_signal_fence(_Py_memory_order_release); \</u></td></tr>
<tr><th id="170">170</th><td><u>            /* fallthrough */ \</u></td></tr>
<tr><th id="171">171</th><td><u>        case _Py_memory_order_relaxed: \</u></td></tr>
<tr><th id="172">172</th><td><u>            *volatile_data = new_val; \</u></td></tr>
<tr><th id="173">173</th><td><u>            break; \</u></td></tr>
<tr><th id="174">174</th><td><u>        \</u></td></tr>
<tr><th id="175">175</th><td><u>        case _Py_memory_order_acquire: \</u></td></tr>
<tr><th id="176">176</th><td><u>        case _Py_memory_order_acq_rel: \</u></td></tr>
<tr><th id="177">177</th><td><u>        case _Py_memory_order_seq_cst: \</u></td></tr>
<tr><th id="178">178</th><td><u>            __asm__ volatile("xchg %0, %1" \</u></td></tr>
<tr><th id="179">179</th><td><u>                         : "+r"(new_val) \</u></td></tr>
<tr><th id="180">180</th><td><u>                         : "m"(atomic_val-&gt;_value) \</u></td></tr>
<tr><th id="181">181</th><td><u>                         : "memory"); \</u></td></tr>
<tr><th id="182">182</th><td><u>            break; \</u></td></tr>
<tr><th id="183">183</th><td><u>        } \</u></td></tr>
<tr><th id="184">184</th><td><u>        _Py_ANNOTATE_IGNORE_WRITES_END(); \</u></td></tr>
<tr><th id="185">185</th><td><u>    })</u></td></tr>
<tr><th id="186">186</th><td></td></tr>
<tr><th id="187">187</th><td><u>#define _Py_atomic_load_explicit(ATOMIC_VAL, ORDER) \</u></td></tr>
<tr><th id="188">188</th><td><u>    __extension__ ({  \</u></td></tr>
<tr><th id="189">189</th><td><u>        __typeof__(ATOMIC_VAL) atomic_val = ATOMIC_VAL; \</u></td></tr>
<tr><th id="190">190</th><td><u>        __typeof__(atomic_val-&gt;_value) result; \</u></td></tr>
<tr><th id="191">191</th><td><u>        volatile __typeof__(result) *volatile_data = &amp;atomic_val-&gt;_value; \</u></td></tr>
<tr><th id="192">192</th><td><u>        _Py_memory_order order = ORDER; \</u></td></tr>
<tr><th id="193">193</th><td><u>        _Py_ANNOTATE_MEMORY_ORDER(atomic_val, order); \</u></td></tr>
<tr><th id="194">194</th><td><u>        \</u></td></tr>
<tr><th id="195">195</th><td><u>        /* Perform the operation. */ \</u></td></tr>
<tr><th id="196">196</th><td><u>        _Py_ANNOTATE_IGNORE_READS_BEGIN(); \</u></td></tr>
<tr><th id="197">197</th><td><u>        switch(order) { \</u></td></tr>
<tr><th id="198">198</th><td><u>        case _Py_memory_order_release: \</u></td></tr>
<tr><th id="199">199</th><td><u>        case _Py_memory_order_acq_rel: \</u></td></tr>
<tr><th id="200">200</th><td><u>        case _Py_memory_order_seq_cst: \</u></td></tr>
<tr><th id="201">201</th><td><u>            /* Loads on x86 are not releases by default, so need a */ \</u></td></tr>
<tr><th id="202">202</th><td><u>            /* thread fence. */ \</u></td></tr>
<tr><th id="203">203</th><td><u>            _Py_atomic_thread_fence(_Py_memory_order_release); \</u></td></tr>
<tr><th id="204">204</th><td><u>            break; \</u></td></tr>
<tr><th id="205">205</th><td><u>        default: \</u></td></tr>
<tr><th id="206">206</th><td><u>            /* No fence */ \</u></td></tr>
<tr><th id="207">207</th><td><u>            break; \</u></td></tr>
<tr><th id="208">208</th><td><u>        } \</u></td></tr>
<tr><th id="209">209</th><td><u>        result = *volatile_data; \</u></td></tr>
<tr><th id="210">210</th><td><u>        switch(order) { \</u></td></tr>
<tr><th id="211">211</th><td><u>        case _Py_memory_order_acquire: \</u></td></tr>
<tr><th id="212">212</th><td><u>        case _Py_memory_order_acq_rel: \</u></td></tr>
<tr><th id="213">213</th><td><u>        case _Py_memory_order_seq_cst: \</u></td></tr>
<tr><th id="214">214</th><td><u>            /* Loads on x86 are automatically acquire operations so */ \</u></td></tr>
<tr><th id="215">215</th><td><u>            /* can get by with just a compiler fence. */ \</u></td></tr>
<tr><th id="216">216</th><td><u>            _Py_atomic_signal_fence(_Py_memory_order_acquire); \</u></td></tr>
<tr><th id="217">217</th><td><u>            break; \</u></td></tr>
<tr><th id="218">218</th><td><u>        default: \</u></td></tr>
<tr><th id="219">219</th><td><u>            /* No fence */ \</u></td></tr>
<tr><th id="220">220</th><td><u>            break; \</u></td></tr>
<tr><th id="221">221</th><td><u>        } \</u></td></tr>
<tr><th id="222">222</th><td><u>        _Py_ANNOTATE_IGNORE_READS_END(); \</u></td></tr>
<tr><th id="223">223</th><td><u>        result; \</u></td></tr>
<tr><th id="224">224</th><td><u>    })</u></td></tr>
<tr><th id="225">225</th><td></td></tr>
<tr><th id="226">226</th><td><u>#elif defined(_MSC_VER)</u> </td></tr>
<tr><th id="227">227</th><td><i>/*  _Interlocked* functions provide a full memory barrier and are therefore</i></td></tr>
<tr><th id="228">228</th><td><i>    enough for acq_rel and seq_cst. If the HLE variants aren't available</i></td></tr>
<tr><th id="229">229</th><td><i>    in hardware they will fall back to a full memory barrier as well.</i></td></tr>
<tr><th id="230">230</th><td><i></i></td></tr>
<tr><th id="231">231</th><td><i>    This might affect performance but likely only in some very specific and</i></td></tr>
<tr><th id="232">232</th><td><i>    hard to meassure scenario.</i></td></tr>
<tr><th id="233">233</th><td><i>*/</i></td></tr>
<tr><th id="234">234</th><td><u>#if defined(_M_IX86) || defined(_M_X64)</u></td></tr>
<tr><th id="235">235</th><td><b>typedef</b> <b>enum</b> _Py_memory_order {</td></tr>
<tr><th id="236">236</th><td>    _Py_memory_order_relaxed,</td></tr>
<tr><th id="237">237</th><td>    _Py_memory_order_acquire,</td></tr>
<tr><th id="238">238</th><td>    _Py_memory_order_release,</td></tr>
<tr><th id="239">239</th><td>    _Py_memory_order_acq_rel,</td></tr>
<tr><th id="240">240</th><td>    _Py_memory_order_seq_cst</td></tr>
<tr><th id="241">241</th><td>} _Py_memory_order;</td></tr>
<tr><th id="242">242</th><td></td></tr>
<tr><th id="243">243</th><td><b>typedef</b> <b>struct</b> _Py_atomic_address {</td></tr>
<tr><th id="244">244</th><td>    <em>volatile</em> uintptr_t _value;</td></tr>
<tr><th id="245">245</th><td>} _Py_atomic_address;</td></tr>
<tr><th id="246">246</th><td></td></tr>
<tr><th id="247">247</th><td><b>typedef</b> <b>struct</b> _Py_atomic_int {</td></tr>
<tr><th id="248">248</th><td>    <em>volatile</em> <em>int</em> _value;</td></tr>
<tr><th id="249">249</th><td>} _Py_atomic_int;</td></tr>
<tr><th id="250">250</th><td></td></tr>
<tr><th id="251">251</th><td></td></tr>
<tr><th id="252">252</th><td><u>#if defined(_M_X64)</u> </td></tr>
<tr><th id="253">253</th><td><u>#define _Py_atomic_store_64bit(ATOMIC_VAL, NEW_VAL, ORDER) \</u></td></tr>
<tr><th id="254">254</th><td><u>    switch (ORDER) { \</u></td></tr>
<tr><th id="255">255</th><td><u>    case _Py_memory_order_acquire: \</u></td></tr>
<tr><th id="256">256</th><td><u>      _InterlockedExchange64_HLEAcquire((__int64 volatile*)ATOMIC_VAL, (__int64)NEW_VAL); \</u></td></tr>
<tr><th id="257">257</th><td><u>      break; \</u></td></tr>
<tr><th id="258">258</th><td><u>    case _Py_memory_order_release: \</u></td></tr>
<tr><th id="259">259</th><td><u>      _InterlockedExchange64_HLERelease((__int64 volatile*)ATOMIC_VAL, (__int64)NEW_VAL); \</u></td></tr>
<tr><th id="260">260</th><td><u>      break; \</u></td></tr>
<tr><th id="261">261</th><td><u>    default: \</u></td></tr>
<tr><th id="262">262</th><td><u>      _InterlockedExchange64((__int64 volatile*)ATOMIC_VAL, (__int64)NEW_VAL); \</u></td></tr>
<tr><th id="263">263</th><td><u>      break; \</u></td></tr>
<tr><th id="264">264</th><td><u>  }</u></td></tr>
<tr><th id="265">265</th><td><u>#else</u></td></tr>
<tr><th id="266">266</th><td><u>#define _Py_atomic_store_64bit(ATOMIC_VAL, NEW_VAL, ORDER) ((void)0);</u></td></tr>
<tr><th id="267">267</th><td><u>#endif</u></td></tr>
<tr><th id="268">268</th><td></td></tr>
<tr><th id="269">269</th><td><u>#define _Py_atomic_store_32bit(ATOMIC_VAL, NEW_VAL, ORDER) \</u></td></tr>
<tr><th id="270">270</th><td><u>  switch (ORDER) { \</u></td></tr>
<tr><th id="271">271</th><td><u>  case _Py_memory_order_acquire: \</u></td></tr>
<tr><th id="272">272</th><td><u>    _InterlockedExchange_HLEAcquire((volatile long*)ATOMIC_VAL, (int)NEW_VAL); \</u></td></tr>
<tr><th id="273">273</th><td><u>    break; \</u></td></tr>
<tr><th id="274">274</th><td><u>  case _Py_memory_order_release: \</u></td></tr>
<tr><th id="275">275</th><td><u>    _InterlockedExchange_HLERelease((volatile long*)ATOMIC_VAL, (int)NEW_VAL); \</u></td></tr>
<tr><th id="276">276</th><td><u>    break; \</u></td></tr>
<tr><th id="277">277</th><td><u>  default: \</u></td></tr>
<tr><th id="278">278</th><td><u>    _InterlockedExchange((volatile long*)ATOMIC_VAL, (int)NEW_VAL); \</u></td></tr>
<tr><th id="279">279</th><td><u>    break; \</u></td></tr>
<tr><th id="280">280</th><td><u>  }</u></td></tr>
<tr><th id="281">281</th><td></td></tr>
<tr><th id="282">282</th><td><u>#if defined(_M_X64)</u></td></tr>
<tr><th id="283">283</th><td><i>/*  This has to be an intptr_t for now.</i></td></tr>
<tr><th id="284">284</th><td><i>    gil_created() uses -1 as a sentinel value, if this returns</i></td></tr>
<tr><th id="285">285</th><td><i>    a uintptr_t it will do an unsigned compare and crash</i></td></tr>
<tr><th id="286">286</th><td><i>*/</i></td></tr>
<tr><th id="287">287</th><td><b>inline</b> intptr_t _Py_atomic_load_64bit(<em>volatile</em> uintptr_t* value, <em>int</em> order) {</td></tr>
<tr><th id="288">288</th><td>    uintptr_t old;</td></tr>
<tr><th id="289">289</th><td>    <b>switch</b> (order) {</td></tr>
<tr><th id="290">290</th><td>    <b>case</b> _Py_memory_order_acquire:</td></tr>
<tr><th id="291">291</th><td>    {</td></tr>
<tr><th id="292">292</th><td>      <b>do</b> {</td></tr>
<tr><th id="293">293</th><td>        old = *value;</td></tr>
<tr><th id="294">294</th><td>      } <b>while</b>(_InterlockedCompareExchange64_HLEAcquire(value, old, old) != old);</td></tr>
<tr><th id="295">295</th><td>      <b>break</b>;</td></tr>
<tr><th id="296">296</th><td>    }</td></tr>
<tr><th id="297">297</th><td>    <b>case</b> _Py_memory_order_release:</td></tr>
<tr><th id="298">298</th><td>    {</td></tr>
<tr><th id="299">299</th><td>      <b>do</b> {</td></tr>
<tr><th id="300">300</th><td>        old = *value;</td></tr>
<tr><th id="301">301</th><td>      } <b>while</b>(_InterlockedCompareExchange64_HLERelease(value, old, old) != old);</td></tr>
<tr><th id="302">302</th><td>      <b>break</b>;</td></tr>
<tr><th id="303">303</th><td>    }</td></tr>
<tr><th id="304">304</th><td>    <b>case</b> _Py_memory_order_relaxed:</td></tr>
<tr><th id="305">305</th><td>      old = *value;</td></tr>
<tr><th id="306">306</th><td>      <b>break</b>;</td></tr>
<tr><th id="307">307</th><td>    <b>default</b>:</td></tr>
<tr><th id="308">308</th><td>    {</td></tr>
<tr><th id="309">309</th><td>      <b>do</b> {</td></tr>
<tr><th id="310">310</th><td>        old = *value;</td></tr>
<tr><th id="311">311</th><td>      } <b>while</b>(_InterlockedCompareExchange64(value, old, old) != old);</td></tr>
<tr><th id="312">312</th><td>      <b>break</b>;</td></tr>
<tr><th id="313">313</th><td>    }</td></tr>
<tr><th id="314">314</th><td>    }</td></tr>
<tr><th id="315">315</th><td>    <b>return</b> old; </td></tr>
<tr><th id="316">316</th><td>}</td></tr>
<tr><th id="317">317</th><td></td></tr>
<tr><th id="318">318</th><td><u>#else</u></td></tr>
<tr><th id="319">319</th><td><u>#define _Py_atomic_load_64bit(ATOMIC_VAL, ORDER) *ATOMIC_VAL</u></td></tr>
<tr><th id="320">320</th><td><u>#endif</u></td></tr>
<tr><th id="321">321</th><td></td></tr>
<tr><th id="322">322</th><td><b>inline</b> <em>int</em> _Py_atomic_load_32bit(<em>volatile</em> <em>int</em>* value, <em>int</em> order) {</td></tr>
<tr><th id="323">323</th><td>    <em>int</em> old;</td></tr>
<tr><th id="324">324</th><td>    <b>switch</b> (order) {</td></tr>
<tr><th id="325">325</th><td>    <b>case</b> _Py_memory_order_acquire:</td></tr>
<tr><th id="326">326</th><td>    {</td></tr>
<tr><th id="327">327</th><td>      <b>do</b> {</td></tr>
<tr><th id="328">328</th><td>        old = *value;</td></tr>
<tr><th id="329">329</th><td>      } <b>while</b>(_InterlockedCompareExchange_HLEAcquire(value, old, old) != old);</td></tr>
<tr><th id="330">330</th><td>      <b>break</b>;</td></tr>
<tr><th id="331">331</th><td>    }</td></tr>
<tr><th id="332">332</th><td>    <b>case</b> _Py_memory_order_release:</td></tr>
<tr><th id="333">333</th><td>    {</td></tr>
<tr><th id="334">334</th><td>      <b>do</b> {</td></tr>
<tr><th id="335">335</th><td>        old = *value;</td></tr>
<tr><th id="336">336</th><td>      } <b>while</b>(_InterlockedCompareExchange_HLERelease(value, old, old) != old);</td></tr>
<tr><th id="337">337</th><td>      <b>break</b>;</td></tr>
<tr><th id="338">338</th><td>    }</td></tr>
<tr><th id="339">339</th><td>    <b>case</b> _Py_memory_order_relaxed:</td></tr>
<tr><th id="340">340</th><td>      old = *value;</td></tr>
<tr><th id="341">341</th><td>      <b>break</b>;</td></tr>
<tr><th id="342">342</th><td>    <b>default</b>:</td></tr>
<tr><th id="343">343</th><td>    {</td></tr>
<tr><th id="344">344</th><td>      <b>do</b> {</td></tr>
<tr><th id="345">345</th><td>        old = *value;</td></tr>
<tr><th id="346">346</th><td>      } <b>while</b>(_InterlockedCompareExchange(value, old, old) != old);</td></tr>
<tr><th id="347">347</th><td>      <b>break</b>;</td></tr>
<tr><th id="348">348</th><td>    }</td></tr>
<tr><th id="349">349</th><td>    }</td></tr>
<tr><th id="350">350</th><td>    <b>return</b> old; </td></tr>
<tr><th id="351">351</th><td>}</td></tr>
<tr><th id="352">352</th><td></td></tr>
<tr><th id="353">353</th><td><u>#define _Py_atomic_store_explicit(ATOMIC_VAL, NEW_VAL, ORDER) \</u></td></tr>
<tr><th id="354">354</th><td><u>  if (sizeof(*ATOMIC_VAL._value) == 8) { \</u></td></tr>
<tr><th id="355">355</th><td><u>    _Py_atomic_store_64bit((volatile long long*)ATOMIC_VAL._value, NEW_VAL, ORDER) } else { \</u></td></tr>
<tr><th id="356">356</th><td><u>    _Py_atomic_store_32bit((volatile long*)ATOMIC_VAL._value, NEW_VAL, ORDER) }</u></td></tr>
<tr><th id="357">357</th><td></td></tr>
<tr><th id="358">358</th><td><u>#define _Py_atomic_load_explicit(ATOMIC_VAL, ORDER) \</u></td></tr>
<tr><th id="359">359</th><td><u>  ( \</u></td></tr>
<tr><th id="360">360</th><td><u>    sizeof(*(ATOMIC_VAL._value)) == 8 ? \</u></td></tr>
<tr><th id="361">361</th><td><u>    _Py_atomic_load_64bit((volatile long long*)ATOMIC_VAL._value, ORDER) : \</u></td></tr>
<tr><th id="362">362</th><td><u>    _Py_atomic_load_32bit((volatile long*)ATOMIC_VAL._value, ORDER) \</u></td></tr>
<tr><th id="363">363</th><td><u>  )</u></td></tr>
<tr><th id="364">364</th><td><u>#elif defined(_M_ARM) || defined(_M_ARM64)</u></td></tr>
<tr><th id="365">365</th><td><b>typedef</b> <b>enum</b> _Py_memory_order {</td></tr>
<tr><th id="366">366</th><td>    _Py_memory_order_relaxed,</td></tr>
<tr><th id="367">367</th><td>    _Py_memory_order_acquire,</td></tr>
<tr><th id="368">368</th><td>    _Py_memory_order_release,</td></tr>
<tr><th id="369">369</th><td>    _Py_memory_order_acq_rel,</td></tr>
<tr><th id="370">370</th><td>    _Py_memory_order_seq_cst</td></tr>
<tr><th id="371">371</th><td>} _Py_memory_order;</td></tr>
<tr><th id="372">372</th><td></td></tr>
<tr><th id="373">373</th><td><b>typedef</b> <b>struct</b> _Py_atomic_address {</td></tr>
<tr><th id="374">374</th><td>    <em>volatile</em> uintptr_t _value;</td></tr>
<tr><th id="375">375</th><td>} _Py_atomic_address;</td></tr>
<tr><th id="376">376</th><td></td></tr>
<tr><th id="377">377</th><td><b>typedef</b> <b>struct</b> _Py_atomic_int {</td></tr>
<tr><th id="378">378</th><td>    <em>volatile</em> <em>int</em> _value;</td></tr>
<tr><th id="379">379</th><td>} _Py_atomic_int;</td></tr>
<tr><th id="380">380</th><td></td></tr>
<tr><th id="381">381</th><td></td></tr>
<tr><th id="382">382</th><td><u>#if defined(_M_ARM64)</u> </td></tr>
<tr><th id="383">383</th><td><u>#define _Py_atomic_store_64bit(ATOMIC_VAL, NEW_VAL, ORDER) \</u></td></tr>
<tr><th id="384">384</th><td><u>    switch (ORDER) { \</u></td></tr>
<tr><th id="385">385</th><td><u>    case _Py_memory_order_acquire: \</u></td></tr>
<tr><th id="386">386</th><td><u>      _InterlockedExchange64_acq((__int64 volatile*)ATOMIC_VAL, (__int64)NEW_VAL); \</u></td></tr>
<tr><th id="387">387</th><td><u>      break; \</u></td></tr>
<tr><th id="388">388</th><td><u>    case _Py_memory_order_release: \</u></td></tr>
<tr><th id="389">389</th><td><u>      _InterlockedExchange64_rel((__int64 volatile*)ATOMIC_VAL, (__int64)NEW_VAL); \</u></td></tr>
<tr><th id="390">390</th><td><u>      break; \</u></td></tr>
<tr><th id="391">391</th><td><u>    default: \</u></td></tr>
<tr><th id="392">392</th><td><u>      _InterlockedExchange64((__int64 volatile*)ATOMIC_VAL, (__int64)NEW_VAL); \</u></td></tr>
<tr><th id="393">393</th><td><u>      break; \</u></td></tr>
<tr><th id="394">394</th><td><u>  }</u></td></tr>
<tr><th id="395">395</th><td><u>#else</u></td></tr>
<tr><th id="396">396</th><td><u>#define _Py_atomic_store_64bit(ATOMIC_VAL, NEW_VAL, ORDER) ((void)0);</u></td></tr>
<tr><th id="397">397</th><td><u>#endif</u></td></tr>
<tr><th id="398">398</th><td></td></tr>
<tr><th id="399">399</th><td><u>#define _Py_atomic_store_32bit(ATOMIC_VAL, NEW_VAL, ORDER) \</u></td></tr>
<tr><th id="400">400</th><td><u>  switch (ORDER) { \</u></td></tr>
<tr><th id="401">401</th><td><u>  case _Py_memory_order_acquire: \</u></td></tr>
<tr><th id="402">402</th><td><u>    _InterlockedExchange_acq((volatile long*)ATOMIC_VAL, (int)NEW_VAL); \</u></td></tr>
<tr><th id="403">403</th><td><u>    break; \</u></td></tr>
<tr><th id="404">404</th><td><u>  case _Py_memory_order_release: \</u></td></tr>
<tr><th id="405">405</th><td><u>    _InterlockedExchange_rel((volatile long*)ATOMIC_VAL, (int)NEW_VAL); \</u></td></tr>
<tr><th id="406">406</th><td><u>    break; \</u></td></tr>
<tr><th id="407">407</th><td><u>  default: \</u></td></tr>
<tr><th id="408">408</th><td><u>    _InterlockedExchange((volatile long*)ATOMIC_VAL, (int)NEW_VAL); \</u></td></tr>
<tr><th id="409">409</th><td><u>    break; \</u></td></tr>
<tr><th id="410">410</th><td><u>  }</u></td></tr>
<tr><th id="411">411</th><td></td></tr>
<tr><th id="412">412</th><td><u>#if defined(_M_ARM64)</u></td></tr>
<tr><th id="413">413</th><td><i>/*  This has to be an intptr_t for now.</i></td></tr>
<tr><th id="414">414</th><td><i>    gil_created() uses -1 as a sentinel value, if this returns</i></td></tr>
<tr><th id="415">415</th><td><i>    a uintptr_t it will do an unsigned compare and crash</i></td></tr>
<tr><th id="416">416</th><td><i>*/</i></td></tr>
<tr><th id="417">417</th><td><b>inline</b> intptr_t _Py_atomic_load_64bit(<em>volatile</em> uintptr_t* value, <em>int</em> order) {</td></tr>
<tr><th id="418">418</th><td>    uintptr_t old;</td></tr>
<tr><th id="419">419</th><td>    <b>switch</b> (order) {</td></tr>
<tr><th id="420">420</th><td>    <b>case</b> _Py_memory_order_acquire:</td></tr>
<tr><th id="421">421</th><td>    {</td></tr>
<tr><th id="422">422</th><td>      <b>do</b> {</td></tr>
<tr><th id="423">423</th><td>        old = *value;</td></tr>
<tr><th id="424">424</th><td>      } <b>while</b>(_InterlockedCompareExchange64_acq(value, old, old) != old);</td></tr>
<tr><th id="425">425</th><td>      <b>break</b>;</td></tr>
<tr><th id="426">426</th><td>    }</td></tr>
<tr><th id="427">427</th><td>    <b>case</b> _Py_memory_order_release:</td></tr>
<tr><th id="428">428</th><td>    {</td></tr>
<tr><th id="429">429</th><td>      <b>do</b> {</td></tr>
<tr><th id="430">430</th><td>        old = *value;</td></tr>
<tr><th id="431">431</th><td>      } <b>while</b>(_InterlockedCompareExchange64_rel(value, old, old) != old);</td></tr>
<tr><th id="432">432</th><td>      <b>break</b>;</td></tr>
<tr><th id="433">433</th><td>    }</td></tr>
<tr><th id="434">434</th><td>    <b>case</b> _Py_memory_order_relaxed:</td></tr>
<tr><th id="435">435</th><td>      old = *value;</td></tr>
<tr><th id="436">436</th><td>      <b>break</b>;</td></tr>
<tr><th id="437">437</th><td>    <b>default</b>:</td></tr>
<tr><th id="438">438</th><td>    {</td></tr>
<tr><th id="439">439</th><td>      <b>do</b> {</td></tr>
<tr><th id="440">440</th><td>        old = *value;</td></tr>
<tr><th id="441">441</th><td>      } <b>while</b>(_InterlockedCompareExchange64(value, old, old) != old);</td></tr>
<tr><th id="442">442</th><td>      <b>break</b>;</td></tr>
<tr><th id="443">443</th><td>    }</td></tr>
<tr><th id="444">444</th><td>    }</td></tr>
<tr><th id="445">445</th><td>    <b>return</b> old; </td></tr>
<tr><th id="446">446</th><td>}</td></tr>
<tr><th id="447">447</th><td></td></tr>
<tr><th id="448">448</th><td><u>#else</u></td></tr>
<tr><th id="449">449</th><td><u>#define _Py_atomic_load_64bit(ATOMIC_VAL, ORDER) *ATOMIC_VAL</u></td></tr>
<tr><th id="450">450</th><td><u>#endif</u></td></tr>
<tr><th id="451">451</th><td></td></tr>
<tr><th id="452">452</th><td><b>inline</b> <em>int</em> _Py_atomic_load_32bit(<em>volatile</em> <em>int</em>* value, <em>int</em> order) {</td></tr>
<tr><th id="453">453</th><td>    <em>int</em> old;</td></tr>
<tr><th id="454">454</th><td>    <b>switch</b> (order) {</td></tr>
<tr><th id="455">455</th><td>    <b>case</b> _Py_memory_order_acquire:</td></tr>
<tr><th id="456">456</th><td>    {</td></tr>
<tr><th id="457">457</th><td>      <b>do</b> {</td></tr>
<tr><th id="458">458</th><td>        old = *value;</td></tr>
<tr><th id="459">459</th><td>      } <b>while</b>(_InterlockedCompareExchange_acq(value, old, old) != old);</td></tr>
<tr><th id="460">460</th><td>      <b>break</b>;</td></tr>
<tr><th id="461">461</th><td>    }</td></tr>
<tr><th id="462">462</th><td>    <b>case</b> _Py_memory_order_release:</td></tr>
<tr><th id="463">463</th><td>    {</td></tr>
<tr><th id="464">464</th><td>      <b>do</b> {</td></tr>
<tr><th id="465">465</th><td>        old = *value;</td></tr>
<tr><th id="466">466</th><td>      } <b>while</b>(_InterlockedCompareExchange_rel(value, old, old) != old);</td></tr>
<tr><th id="467">467</th><td>      <b>break</b>;</td></tr>
<tr><th id="468">468</th><td>    }</td></tr>
<tr><th id="469">469</th><td>    <b>case</b> _Py_memory_order_relaxed:</td></tr>
<tr><th id="470">470</th><td>      old = *value;</td></tr>
<tr><th id="471">471</th><td>      <b>break</b>;</td></tr>
<tr><th id="472">472</th><td>    <b>default</b>:</td></tr>
<tr><th id="473">473</th><td>    {</td></tr>
<tr><th id="474">474</th><td>      <b>do</b> {</td></tr>
<tr><th id="475">475</th><td>        old = *value;</td></tr>
<tr><th id="476">476</th><td>      } <b>while</b>(_InterlockedCompareExchange(value, old, old) != old);</td></tr>
<tr><th id="477">477</th><td>      <b>break</b>;</td></tr>
<tr><th id="478">478</th><td>    }</td></tr>
<tr><th id="479">479</th><td>    }</td></tr>
<tr><th id="480">480</th><td>    <b>return</b> old; </td></tr>
<tr><th id="481">481</th><td>}</td></tr>
<tr><th id="482">482</th><td></td></tr>
<tr><th id="483">483</th><td><u>#define _Py_atomic_store_explicit(ATOMIC_VAL, NEW_VAL, ORDER) \</u></td></tr>
<tr><th id="484">484</th><td><u>  if (sizeof(*ATOMIC_VAL._value) == 8) { \</u></td></tr>
<tr><th id="485">485</th><td><u>    _Py_atomic_store_64bit(ATOMIC_VAL._value, NEW_VAL, ORDER) } else { \</u></td></tr>
<tr><th id="486">486</th><td><u>    _Py_atomic_store_32bit(ATOMIC_VAL._value, NEW_VAL, ORDER) }</u> </td></tr>
<tr><th id="487">487</th><td></td></tr>
<tr><th id="488">488</th><td><u>#define _Py_atomic_load_explicit(ATOMIC_VAL, ORDER) \</u></td></tr>
<tr><th id="489">489</th><td><u>  ( \</u></td></tr>
<tr><th id="490">490</th><td><u>    sizeof(*(ATOMIC_VAL._value)) == 8 ? \</u></td></tr>
<tr><th id="491">491</th><td><u>    _Py_atomic_load_64bit(ATOMIC_VAL._value, ORDER) : \</u></td></tr>
<tr><th id="492">492</th><td><u>    _Py_atomic_load_32bit(ATOMIC_VAL._value, ORDER) \</u></td></tr>
<tr><th id="493">493</th><td><u>  )</u></td></tr>
<tr><th id="494">494</th><td><u>#endif</u></td></tr>
<tr><th id="495">495</th><td><u>#else  /* !gcc x86  !_msc_ver */</u></td></tr>
<tr><th id="496">496</th><td><b>typedef</b> <b>enum</b> _Py_memory_order {</td></tr>
<tr><th id="497">497</th><td>    _Py_memory_order_relaxed,</td></tr>
<tr><th id="498">498</th><td>    _Py_memory_order_acquire,</td></tr>
<tr><th id="499">499</th><td>    _Py_memory_order_release,</td></tr>
<tr><th id="500">500</th><td>    _Py_memory_order_acq_rel,</td></tr>
<tr><th id="501">501</th><td>    _Py_memory_order_seq_cst</td></tr>
<tr><th id="502">502</th><td>} _Py_memory_order;</td></tr>
<tr><th id="503">503</th><td></td></tr>
<tr><th id="504">504</th><td><b>typedef</b> <b>struct</b> _Py_atomic_address {</td></tr>
<tr><th id="505">505</th><td>    uintptr_t _value;</td></tr>
<tr><th id="506">506</th><td>} _Py_atomic_address;</td></tr>
<tr><th id="507">507</th><td></td></tr>
<tr><th id="508">508</th><td><b>typedef</b> <b>struct</b> _Py_atomic_int {</td></tr>
<tr><th id="509">509</th><td>    <em>int</em> _value;</td></tr>
<tr><th id="510">510</th><td>} _Py_atomic_int;</td></tr>
<tr><th id="511">511</th><td><i>/* Fall back to other compilers and processors by assuming that simple</i></td></tr>
<tr><th id="512">512</th><td><i>   volatile accesses are atomic.  This is false, so people should port</i></td></tr>
<tr><th id="513">513</th><td><i>   this. */</i></td></tr>
<tr><th id="514">514</th><td><u>#define _Py_atomic_signal_fence(/*memory_order*/ ORDER) ((void)0)</u></td></tr>
<tr><th id="515">515</th><td><u>#define _Py_atomic_thread_fence(/*memory_order*/ ORDER) ((void)0)</u></td></tr>
<tr><th id="516">516</th><td><u>#define _Py_atomic_store_explicit(ATOMIC_VAL, NEW_VAL, ORDER) \</u></td></tr>
<tr><th id="517">517</th><td><u>    ((ATOMIC_VAL)-&gt;_value = NEW_VAL)</u></td></tr>
<tr><th id="518">518</th><td><u>#define _Py_atomic_load_explicit(ATOMIC_VAL, ORDER) \</u></td></tr>
<tr><th id="519">519</th><td><u>    ((ATOMIC_VAL)-&gt;_value)</u></td></tr>
<tr><th id="520">520</th><td><u>#endif</u></td></tr>
<tr><th id="521">521</th><td></td></tr>
<tr><th id="522">522</th><td><i>/* Standardized shortcuts. */</i></td></tr>
<tr><th id="523">523</th><td><u>#define _Py_atomic_store(ATOMIC_VAL, NEW_VAL) \</u></td></tr>
<tr><th id="524">524</th><td><u>    _Py_atomic_store_explicit(ATOMIC_VAL, NEW_VAL, _Py_memory_order_seq_cst)</u></td></tr>
<tr><th id="525">525</th><td><u>#define _Py_atomic_load(ATOMIC_VAL) \</u></td></tr>
<tr><th id="526">526</th><td><u>    _Py_atomic_load_explicit(ATOMIC_VAL, _Py_memory_order_seq_cst)</u></td></tr>
<tr><th id="527">527</th><td></td></tr>
<tr><th id="528">528</th><td><i>/* Python-local extensions */</i></td></tr>
<tr><th id="529">529</th><td></td></tr>
<tr><th id="530">530</th><td><u>#define _Py_atomic_store_relaxed(ATOMIC_VAL, NEW_VAL) \</u></td></tr>
<tr><th id="531">531</th><td><u>    _Py_atomic_store_explicit(ATOMIC_VAL, NEW_VAL, _Py_memory_order_relaxed)</u></td></tr>
<tr><th id="532">532</th><td><u>#define _Py_atomic_load_relaxed(ATOMIC_VAL) \</u></td></tr>
<tr><th id="533">533</th><td><u>    _Py_atomic_load_explicit(ATOMIC_VAL, _Py_memory_order_relaxed)</u></td></tr>
<tr><th id="534">534</th><td><u>#<span data-ppcond="3">endif</span>  /* Py_BUILD_CORE */</u></td></tr>
<tr><th id="535">535</th><td><u>#<span data-ppcond="1">endif</span>  /* Py_ATOMIC_H */</u></td></tr>
<tr><th id="536">536</th><td></td></tr>
</table><hr/><p id='footer'>
Generated while processing <a href='../Modules/_asynciomodule.c.html'>codebrowser/Modules/_asynciomodule.c</a><br/>Generated on <em>2017-Aug-29</em> from project codebrowser revision <em>v3.6.0b2-99580-g07f1658</em><br />Powered by <a href='https://woboq.com'><img alt='Woboq' src='https://code.woboq.org/woboq-16.png' width='41' height='16' /></a> <a href='https://code.woboq.org'>Code Browser</a> 2.1
<br/>Generator usage only permitted with license.</p>
</div></body></html>
